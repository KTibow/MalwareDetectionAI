import glob
import multiprocessing
import re
from sklearn import tree
import time, pickle

all_files = glob.glob("*/*.jar")


def process_file(file, segments):
    print("starting", file)
    with open(file, "rb") as f:
        file_bytes = f.read()
        matches = set(re.findall(b"[a-zA-Z0-9_]+", file_bytes))
        results = [seg in matches for seg in segments]
        classification = "malware" if file.startswith("rats") else "benign"
    print("finished", file)
    return results, classification


print("finding sample segments")
segments = {}
i = 0
for file in all_files:
    print(i, "/", len(all_files))
    with open(file, "rb") as f:
        file_bytes = f.read()
        matches = set(re.findall(b"[a-zA-Z0-9_]+", file_bytes))
        for match in matches:
            segments[match] = segments.get(match, 0) + 1
    i += 1
segments = [k for k, v in segments.items() if v > 2]
segments_set = set(segments)
print(len(segments))

print("testing sample segments")
classifier = tree.DecisionTreeClassifier(max_depth=5)
data = {"input_data": [], "classification": []}
pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())
for file in all_files:
    pool.apply_async(
        process_file,
        args=(file, segments),
        callback=lambda x: data["input_data"].append(x[0])
        or data["classification"].append(x[1]),
    )
pool.close()
pool.join()

print("fitting classifier")
classifier.fit(data["input_data"], data["classification"])
classifier_result = tree.export_text(classifier, feature_names=segments)
print(classifier_result)
print("saving classifier")
with open(f"classifier{time.time()}.pkl", "wb") as f:
    pickle.dump(classifier, f)
